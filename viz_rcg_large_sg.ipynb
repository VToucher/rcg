{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7665ccc-4b78-42d4-984f-be97e52e49f0",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f687283-ac25-443f-9404-86af90232665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/rcg/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"5\" \n",
    "os.environ['http_proxy'] = '10.106.130.4:3128'\n",
    "os.environ['https_proxy'] = '10.106.130.4:3128'\n",
    "import time\n",
    "import socket\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.distributions import MultivariateNormal\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from pixel_generator.mage import models_mage\n",
    "from PIL import Image\n",
    "from imagenet_clstolabel import IMGNET_CLASS2LABEL\n",
    "from IPython.display import display\n",
    "import lpips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d4c5e77-07f4-4c0a-a02f-b9f4652b203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_torchimage(image):\n",
    "    image = torch.clamp(image, 0, 1)\n",
    "    image_np = image.detach().cpu().numpy().transpose([1, 2, 0])\n",
    "    image_np = Image.fromarray(np.uint8(image_np*255))\n",
    "    display(image_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e39890",
   "metadata": {},
   "source": [
    "<-- ----------------------------------------------------------------------- -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba1832e",
   "metadata": {},
   "source": [
    "# Large version inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4260cb2-dba5-4eb8-9796-9df6a3dd61e2",
   "metadata": {},
   "source": [
    "## 1. Load pre-trained encoder, RDM and MAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98c40a93-8fab-4804-8a91-1ee387da32a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use representation as condition!\n",
      "Loading model from final_ckpts/rdm-mocov3vitl-clscond.pth\n",
      "RDM: Running in x0-prediction mode\n",
      "DiffusionWrapper has 72.18 M params.\n",
      "Keeping EMAs of 156.\n",
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "Strict load\n",
      "Restored from vqgan-ckpts/vqgan_jax_strongaug.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Initialize RCG-L\n",
    "class_cond = True\n",
    "if class_cond:\n",
    "    rdm_ckpt_path = 'final_ckpts/rdm-mocov3vitl-clscond.pth'\n",
    "    rdm_cfg = 'config/rdm/mocov3vitl_simplemlp_l12_w1536_classcond.yaml'\n",
    "else:\n",
    "    rdm_ckpt_path = 'final_ckpts/rdm-mocov3vitl.pth'\n",
    "    rdm_cfg = 'config/rdm/mocov3vitl_simplemlp_l12_w1536.yaml'\n",
    "\n",
    "# minority guidance args\n",
    "mg_kwargs = {\n",
    "    'use_ms_grad': True,\n",
    "    'norm_for_mg': 2.0,\n",
    "    't_mid': -1.0,  # -1.0 for no early stop\n",
    "    'mg_scale': 0.15,\n",
    "    'p_ratio': 0.5,\n",
    "    'num_mc_samples': 1,\n",
    "    'mg_scale_type': 'var',\n",
    "    'use_normed_grad': True,\n",
    "    'use_lpips': False,\n",
    "    'inter_rate': 1,\n",
    "}\n",
    "if mg_kwargs['use_lpips']:\n",
    "    loss_lpips = lpips.LPIPS(net='alex').cuda()\n",
    "    mg_kwargs['loss_lpips'] = loss_lpips\n",
    "model = models_mage.mage_vit_large_patch16(mask_ratio_mu=0.75, mask_ratio_std=0.25,\n",
    "                                           mask_ratio_min=0.5, mask_ratio_max=1.0,\n",
    "                                           vqgan_ckpt_path='vqgan-ckpts/vqgan_jax_strongaug.ckpt',\n",
    "                                           use_rep=True, rep_dim=256, rep_drop_prob=0.1,\n",
    "                                           use_class_label=False,\n",
    "                                           pretrained_enc_arch='mocov3_vit_large',\n",
    "                                           pretrained_enc_path='pretrained_enc_ckpts/mocov3/vitl.pth.tar',\n",
    "                                           pretrained_enc_proj_dim=256,\n",
    "                                           pretrained_enc_withproj=True,\n",
    "                                           pretrained_rdm_ckpt=rdm_ckpt_path,\n",
    "                                           pretrained_rdm_cfg=rdm_cfg,\n",
    "                                           mg_kwargs=mg_kwargs)\n",
    "checkpoint = torch.load(os.path.join('final_ckpts/mage-l.pth'), map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model'], strict=True)\n",
    "model.cuda()\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e46dda-a436-48f6-8ffc-53b0d73af0f9",
   "metadata": {},
   "source": [
    "### 2. Image Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd47de61-98e4-4311-980f-53ec7083c0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(7)\n",
    "# np.random.seed(7)\n",
    "\n",
    "n_image_to_gen = 2\n",
    "rdm_steps = 250\n",
    "rdm_eta = 1.0\n",
    "mage_temp = 11.0\n",
    "mage_steps = 20\n",
    "cfg = 6.0  # 6.0\n",
    "\n",
    "if class_cond:\n",
    "    for class_label in [1, 323, 985]:\n",
    "        print(\"{}: {}\".format(class_label, IMGNET_CLASS2LABEL[class_label]))\n",
    "        class_label = class_label * torch.ones(1).cuda().long()\n",
    "        for i in range(n_image_to_gen):\n",
    "            gen_images, _ = model.gen_image(1, num_iter=mage_steps, choice_temperature=mage_temp, sampled_rep=None, rdm_steps=rdm_steps, eta=rdm_eta, cfg=cfg, class_label=class_label)\n",
    "            viz_torchimage(gen_images[0])\n",
    "\n",
    "else:\n",
    "    for i in range(n_image_to_gen):\n",
    "        gen_images, _ = model.gen_image(1, num_iter=mage_steps, choice_temperature=mage_temp, sampled_rep=None, rdm_steps=rdm_steps, eta=rdm_eta, cfg=cfg, class_label=None)\n",
    "        viz_torchimage(gen_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caa67232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_data: 1281167\n",
      "num_classes: 1000\n"
     ]
    }
   ],
   "source": [
    "# get train loader\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "bsz = 1\n",
    "transform = transforms.Compose([\n",
    "            transforms.Resize(256, interpolation=3),\n",
    "            transforms.CenterCrop(256),\n",
    "            transforms.ToTensor()])\n",
    "\n",
    "dataset = datasets.ImageFolder('/root/datasets/imagenet/imagenet1k_train/', transform=transform)\n",
    "print('num_data:', len(dataset))\n",
    "print('num_classes:', len(dataset.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26ee4ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 8, 18, 21, 23, 42, 78, 85, 94, 105, 107, 113, 124, 130, 148, 151, 272, 281, 288, 291, 292, 301, 308, 310, 311, 323, 327, 331, 333, 337, 340, 341, 345, 352, 357, 360, 366, 388, 394, 401, 403, 407, 411, 414, 417, 420, 425, 429, 430, 437, 446, 462, 470, 483, 488, 492, 497, 498, 516, 525, 526, 538, 541, 549, 561, 562, 578, 587, 608, 609, 616, 620, 621, 624, 629, 643, 646, 650, 651, 657, 677, 711, 721, 742, 748, 764, 774, 783, 819, 827, 843, 851, 866, 872, 879, 889, 902, 913, 937, 949]\n"
     ]
    }
   ],
   "source": [
    "label_dict = dataset.class_to_idx\n",
    "f1 = ['n01498041', 'n01514859', 'n01582220', 'n01608432', 'n01616318',\n",
    "          'n01687978', 'n01776313', 'n01806567', 'n01833805', 'n01882714',\n",
    "          'n01910747', 'n01944390', 'n01985128', 'n02007558', 'n02071294',\n",
    "          'n02085620', 'n02114855', 'n02123045', 'n02128385', 'n02129165',\n",
    "          'n02129604', 'n02165456', 'n02190166', 'n02219486', 'n02226429',\n",
    "          'n02279972', 'n02317335', 'n02326432', 'n02342885', 'n02363005',\n",
    "          'n02391049', 'n02395406', 'n02403003', 'n02422699', 'n02442845',\n",
    "          'n02444819', 'n02480855', 'n02510455', 'n02640242', 'n02672831',\n",
    "          'n02687172', 'n02701002', 'n02730930', 'n02769748', 'n02782093',\n",
    "          'n02787622', 'n02793495', 'n02799071', 'n02802426', 'n02814860',\n",
    "          'n02840245', 'n02906734', 'n02948072', 'n02980441', 'n02999410',\n",
    "          'n03014705', 'n03028079', 'n03032252', 'n03125729', 'n03160309',\n",
    "          'n03179701', 'n03220513', 'n03249569', 'n03291819', 'n03384352',\n",
    "          'n03388043', 'n03450230', 'n03481172', 'n03594734', 'n03594945',\n",
    "          'n03627232', 'n03642806', 'n03649909', 'n03661043', 'n03676483',\n",
    "          'n03724870', 'n03733281', 'n03759954', 'n03761084', 'n03773504',\n",
    "          'n03804744', 'n03916031', 'n03938244', 'n04004767', 'n04026417',\n",
    "          'n04090263', 'n04133789', 'n04153751', 'n04296562', 'n04330267',\n",
    "          'n04371774', 'n04404412', 'n04465501', 'n04485082', 'n04507155',\n",
    "          'n04536866', 'n04579432', 'n04606251', 'n07714990', 'n07745940']\n",
    "imgnet100_label = [label_dict[i] for i in f1]\n",
    "print(imgnet100_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
